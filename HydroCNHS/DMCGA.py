from .SystemConrol import loadConfig
from joblib import Parallel, delayed    # For parallelization
import numpy as np
import pickle
import os

r"""
Inputs = {"ParName":[], 
          "ParBound":[],  # [upper, low] or [4, 6, 9] Even for category type, it has to be numbers!
          "ParType":[],   # real or category
          "ParWeight":[]}   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Not yet written into the main code.
          
Config = {"NumSP":1,
          "PopSize": 30,            # Must be even.
          "MaxGen": 100,
          "SamplingMethod": "MC",
          "Tolerance":0.2,
          "NumEllite": 1,           # Ellite number for each SP. At least 1.
          "MutProb": 0.3,           # Mutation probability.
          "DropRecord": True,       # Population record will be dropped. However, ALL simulated results will remain. 
          "ParalCores": 2/None      # This will overwrite system config.
          }
"""
class PreDMCGA_Inputs(object):
    def __init__(self):
        pass  
    def getFormatter(self):
        pass
        
class DMCGA(object):
    def __init__(self, LossFunc, Inputs, Config, Formatter, Continue = None):
        if Continue is not None:
            # Load autoSave pickle file!
            pass
        
        # Populate class attributions.
        self.LossFunc = LossFunc            # Loss function LossFunc(pop, Formatter, SubWD = None).
                                             #pop is a parameter vector. 
                                             #SubWD is a subfolder directory for storing HydroCNHS simulation results if needed.
                                             #Lower bound of return value has to be 0.
        self.Inputs = Inputs                # Input ductionary containing ParName, ParBound, and ParType.
        self.Config = Config                # Configuration for DMCGA.
        self.Formatter = Formatter          # Formatter is to convert pop back into model format for HydroCNHS simulation. 
                                             #It can be generated by PreDMCGA_Inputs.getFormatter()
        self.SysConfig = loadConfig()        #Load system config => Config.yaml (Default parallelization setting)
        self.NumPar = len(Inputs["ParName"])
        
        #---------- Auto save section ----------
        if Continue is None:
            # Generate index lists for later for loop and readibility.
            self.SPList = ["SP0"] + ["SP"+str(i+1) for i in range(Config["NumSP"])]
            
            # Populate initial counter.
            self.CurrentGen = 0
            
            # Initialize variables storage.
            self.Pop = {}           # Population of parameter set. Pop[gen][sp][k,s]
            self.PopRes = {}        # Simulation results (Loss values and min distance, D). PopRes[gen][sp][Loss or D]
            self.SP = {}            # SP[gen]
            self.SP0Best = []       # Store best result of SP0 (master).  
            
            # Calculate scales for parameter normalization.
            self.BoundScale = []
            for i, ty in enumerate(Inputs["ParType"]):
                if ty == "real":
                    self.BoundScale.append(Inputs["ParBound"][i][1] - Inputs["ParBound"][i][0])
                elif ty == "category":
                    self.BoundScale.append(np.max(Inputs["ParBound"][i]) - np.min(Inputs["ParBound"][i]))
            self.BoundScale = np.array(self.BoundScale)     # Store in array type. 
        #---------------------------------------

    def MCSample(self, pop, ParBound, ParType):
        """Generate samples using Monte Carlo method.

        Args:
            pop (Array): 2D array. [PopSize, NumPar]
            NumPar (int): Number of parameters.
            ParBound (list): List of bounds for each parameters.
            ParType (list): List of parameter types. ["real" or "category"]

        Returns:
            array: Populated pop array.
        """
        PopSize = pop.shape[0]      # pop = [PopSize, NumPar]
        NumPar = pop.shape[1]
        for i in range(NumPar):
            if ParType[i] == "real":
                pop[:,i] = np.random.uniform(ParBound[i][0], ParBound[i][1], size = PopSize)  
            elif ParType[i] == "category":
                pop[:,i] = np.random.choice(ParBound[i], size = PopSize)
        return pop 
    
    def initialize(self, SamplingMethod = "MC", InitialPop = None):
        PopSize = self.Config["PopSize"]
        NumPar = self.NumPar
        ParBound = self.Inputs["ParBound"]
        ParType =  self.Inputs["ParType"]

        # Initialize storage space for generation 0.
        self.Pop[0] = {}
        self.PopRes[0] = {}
        self.SP[0] = {}
        
        # Populate pop for each SP.
        if InitialPop is not None:      # Initialize parameters according to selected sampling method.
            for sp in self.SPList:
                pop = np.zeros((PopSize, NumPar))  # Create 2D array population for single generation.
                if SamplingMethod == "MC":
                    self.Pop[0][sp] = self.MCSample(pop, ParBound, ParType)
        else:                           # Initialize parameters with user inputs.
            self.Pop[0] = InitialPop
        
        # Initialize storage space for each SP
        for sp in self.SPList:
            self.PopRes[0][sp] = {}
            self.SP[0][sp] = {}
        
    def nextGen(self):
        LossFunc = self.LossFunc
        Formatter = self.Formatter
        SubWD = None
        CurrentGen = self.CurrentGen
        PopSize = self.Config["PopSize"]
        SPList = self.SPList
        NumSP = self.Config["NumSP"]
        NumPar = self.NumPar
        NumEllite = self.Config["NumEllite"]
        
        
        
        # Load parallelization setting (from user or system config)
        ParalCores = self.Config.get("ParalCores")
        if ParalCores is None:      # If user didn't specify, then we will use system default cores.
            ParalCores = self.SysConfig["Parallelization"]["Cores_DMCGA"]
        ParalVerbose = self.SysConfig["Parallelization"]["verbose"]
        
        #---------- Evaluation (Min) ----------
        # Note: Since HydroCHNS is a stochastic model, we will re simulate the ellite parameter set!!
        # In future, we can have an option for this to further reduce computational efficiency.
        # Evalute objective funtion (Loss function)
        # LossFunc(pop, Formatter, SubWD = None)
        LossParel = Parallel(n_jobs = ParalCores, verbose = ParalVerbose) \
                           ( delayed(LossFunc)\
                             (self.Pop[CurrentGen][sp][k], Formatter, SubWD) \
                             for sp in SPList for k in range(PopSize) )  # Still go through entire Pop including ellites.
        # Get results
        for i, sp in enumerate(SPList):    # To fit two level for loop in joblib assignment.
            self.PopRes[CurrentGen][sp]["Loss"] = LossParel[i*PopSize : (i+1)*PopSize] 
        #--------------------------------------
        
        #---------- Feasibility ----------
        # We define 1: feasible and 0: infeasible
        # Get the best sol from SP0
        SP0BestIndex = np.argmin(self.PopRes[CurrentGen]["SP0"])
        SP0Best = self.PopRes[CurrentGen]["SP0"][SP0BestIndex]
        self.SP0Best.append(SP0Best)
        
        # Determine the feasibility of each solution.
        Tol = self.Config["Tolerance"]
        for sp in SPList:    
            Feasibility = np.zeros(PopSize)
            Feasibility[self.PopRes[CurrentGen][sp]["Loss"] <= SP0Best*Tol] = 1   # Only valid when lower bound is zero
            self.PopRes[CurrentGen][sp]["Feasibility"] = Feasibility
        #---------------------------------
        
        #---------- Diversity ----------
        # Calculate fitness-weighted centriod 
        for sp in SPList[1:]:   # No SP0
            # Calculate fitness weight using Loss. Lowest loss => 1; Highest loss => 0.
            Loss_sp = self.PopRes[CurrentGen][sp]["Loss"]
            temp = Loss_sp.argsort()
            ranks = np.empty_like(temp)
            ranks[temp] = (PopSize-1 - np.arange(PopSize))      # Reverse ranks.
            self.weight_fitness[sp] = ranks = ranks/(PopSize-1) # Turn into linear scaling.
            # Average over pop to calculate centroid parameter set.
            pop_sp = self.Pop[CurrentGen][sp]                   # [PopSize, NumPar]
            pop_sp_w = np.multiply(pop_sp, self.weight_fitness[sp].reshape(PopSize,1))  # Broadcast weights into pop_sp
            self.SP[CurrentGen][sp]["Centroid"] = pop_sp_w.mean(axis = 0)   # Take average over PopSize (axis = 0)
            self.SP[CurrentGen][sp]["NormalizedCentroid"] = np.divide(self.SP[CurrentGen][sp]["Centroid"].reshape(1, NumPar),\
                                                                      self.BoundScale.reshape(1, NumPar))
        # Calculate minimum distance Dmin over q != p (No SP0)
        for sp in enumerate(SPList[1:]):            # No SP0
            Distance = np.zeros((PopSize, NumSP))
            pop_sp = self.Pop[CurrentGen][sp]                   # [PopSize, NumPar]
            Nor_pop_sp = np.divide(pop_sp, self.BoundScale.reshape(1, NumPar))
            for i, sp_q in enumerate(SPList[1:]):   # No SP0
                if sp == sp_q:
                    Distance[:,i] = 1000000     # Assign a large number so it will never be chose when finding min.
                    # Calculate self distance.
                    Nor_centroid_sp_q = self.SP[CurrentGen][sp_q]["NormalizedCentroid"]
                    d = np.subtract(Nor_pop_sp, Nor_centroid_sp_q.reshape(1,NumPar), axis = 1)
                    self.PopRes[CurrentGen][sp]["SelfD"] = np.linalg.norm(d, axis = 1)         # l2norm 
                else:
                    Nor_centroid_sp_q = self.SP[CurrentGen][sp_q]["NormalizedCentroid"]
                    d = np.subtract(Nor_pop_sp, Nor_centroid_sp_q.reshape(1,NumPar), axis = 1)
                    Distance[:,i] = np.linalg.norm(d, axis = 1)         # l2norm 
            Dmin = Distance.min(axis = 1)  # For each k in pop, pick the min distance over SP q!=p.
            self.PopRes[CurrentGen][sp]["Dmin"] = Dmin
        #-------------------------------
        
        #---------- Selection ----------
        # Select ellites fpr each SP
        ElliteIndex = {}
        for sp in SPList:
            Loss = self.PopRes[CurrentGen][sp]["Loss"]
            if sp == "SP0":     # Select based on loss only.
                # argpartition has better efficient in searching n smallest values' index. Linear time.
                ElliteIndex[sp] = np.argpartition(Loss, NumEllite)[:NumEllite]
            else:               # Select the most distant feasible solution.
                Feasibility_sp = self.PopRes[CurrentGen][sp]["Feasibility"]
                if np.sum(Feasibility_sp) <= NumEllite:     # Not enough feasible solutions.
                    ElliteIndex[sp] = np.argpartition(Loss, NumEllite)[:NumEllite]  # Based on loss only. All feasible sols will be selected.
                else:
                    Dmin_sp = self.PopRes[CurrentGen][sp]["Dmin"]
                    Dmin_sp = Dmin_sp*Feasibility_sp    # All Dmin of infeasible sols will become 0. Therefore, no chance to be selected.
                    ElliteIndex[sp] = np.argpartition(Loss, -NumEllite)[-NumEllite:]    # return n largest Dmin index.
    
        # Select parents for each SP
        # Binary tournament => Create a population of parents that is the same size as the original population PopSize.
        ParentIndex = {}
        for sp in SPList:
            ParentIndex[sp] = np.zeros(PopSize)
            CompetitorPair = np.random.randint(low = 0, high = PopSize, size=(PopSize,2)) # Randomly PopSize pairs (2 individuals). 
            Feasibility_sp = self.PopRes[CurrentGen][sp]["Feasibility"]
            TotalFeasibility_sp = np.sum(Feasibility_sp)    # How many feasible sols in total.
            
            if sp == "SP0" or TotalFeasibility_sp < 0.5*PopSize:    # If is SP0 or majority of pop is infeasible solution.
                Loss = self.PopRes[CurrentGen][sp]["Loss"]
                for k in range(PopSize):        # Select based on loss only.
                    pair = CompetitorPair[k,:]
                    ParentIndex[sp][k] = pair[  np.argmin( [Loss[pair[0]],  Loss[pair[1]]] )  ] 
            else:   # ~SP0
                Dmin_sp = self.PopRes[CurrentGen][sp]["Dmin"]
                Loss = self.PopRes[CurrentGen][sp]["Loss"]
                for k in range(PopSize):
                    pair = CompetitorPair[k,:]
                    pair_feasibility = [ Feasibility_sp[pair[0]],  Feasibility_sp[pair[1]] ]
                    SumFeasibility = np.sum(pair_feasibility)
                    if SumFeasibility == 1:     # One feasible sol: Select the feasible sol
                        ParentIndex[sp] = pair[np.where(pair_feasibility == 1)]
                    elif SumFeasibility == 2:   # Two feasible sols: Select larger Dmin if both are feasible.
                        ParentIndex[sp] = pair[  np.argmax(  [Dmin_sp[pair[0]], Dmin_sp[pair[1]]]  )  ]
                    elif SumFeasibility == 0:   # None feasible sol: Select lower loss
                        pair = CompetitorPair[k,:]
                        ParentIndex[sp][k] = pair[  np.argmin( [Loss[pair[0]],  Loss[pair[1]]] )  ] 
        #-------------------------------
        
        #---------- Evolve ----------
        MutProb = self.Config["MutProb"]
        
        def UniformCrossover(parent1, parent2):
            child = np.zeros(NumPar)
            from1 = np.random.randint(0, 2, size = NumPar) == 0
            child[from1] = parent1[from1]
            child[~from1] = parent2[~from1]
            return child
        
        def Mutation(child):
            mut = np.random.binomial(n = 1, p = MutProb, size = NumPar) == 1
            MutSample_MC = self.MCSample(np.zeros((1,NumPar)), self.Inputs["ParBound"], self.Inputs["ParType"])
            child[mut] = MutSample_MC[mut]
            return child
        
        def Mutation_middle(child, parent1, parent2):
            mut = np.random.binomial(n = 1, p = MutProb, size = NumPar) == 1
            MutSample_MC = self.MCSample(np.zeros((1,NumPar)), self.Inputs["ParBound"], self.Inputs["ParType"])
            ratio = np.random.random(NumPar)
            interval = np.abs(parent1 - parent2)
            P1_less_P2 = parent1 < parent2
            P2_less_P1 = parent2 < parent1
            P1_eq_P2 = parent2 == parent1
            Category = self.Inputs["ParType"] == "category"
            child[P1_less_P2] = parent1[P1_less_P2] + ratio[P1_less_P2]*interval[P1_less_P2]
            child[P2_less_P1] = parent2[P2_less_P1] + ratio[P2_less_P1]*interval[P2_less_P1]
            child[P1_eq_P2] = MutSample_MC[P1_eq_P2]
            child[Category] = MutSample_MC[Category]
            return child
        
        self.Pop[CurrentGen+1] = {}
        for sp in SPList:
            self.Pop[CurrentGen+1][sp] = np.zeros((PopSize, NumPar))
            Pop_sp = self.Pop[CurrentGen][sp]
            ParentIndex_sp = ParentIndex[sp]
            # Uniform crossover
            for p in range(int(PopSize/2)):     # PopSize must be even.
                parent1 = Pop_sp[ParentIndex_sp[2*p]]
                parent2 = Pop_sp[ParentIndex_sp[2*p+1]]
                child1 = UniformCrossover(parent1, parent2)
                child2 = UniformCrossover(parent1, parent2)
                child1 = Mutation(child1)
                child2 = Mutation_middle(child2, parent1, parent2)
                self.Pop[CurrentGen+1][sp][2*p] = child1
                self.Pop[CurrentGen+1][sp][2*p+1] = child2
        #----------------------------
        
        #---------- Prepare For Next Gen ----------
        self.PopRes[CurrentGen+1] = {}
        self.SP[CurrentGen+1] = {}
        for sp in self.SPList:
            self.PopRes[CurrentGen+1][sp] = {}
            self.SP[CurrentGen+1][sp] = {}
        self.CurrentGen += 1                    # Next generation
        #------------------------------------------
        return None
    
    def dropRecord(self):
        if self.Config["DropRecord"]:
            del self.Pop[self.CurrentGen-1]
        return None
    
    def autoSave(self):
        dictionary = self.__dict__.copy()
        # dictionary.pop('logger', None)  # handler cannot be pickled.
        # with open(os.path.join(path, "GAobject.pickle"), 'wb') as outfile:
        #     pickle.dump(dictionary, outfile)
        return None
    
    def run(self, InitialPop = None):
        SamplingMethod = self.Config["SamplingMethod"]
        MaxGen = self.Config["MaxGen"]
        
        self.initialize(SamplingMethod, InitialPop)
        while self.CurrentGen <= MaxGen:
            self.nextGen()
            self.dropRecord()
            self.autoSave()
            
        del self.Pop[self.CurrentGen]   # Delete Pop with gen index = (MaxGen+1 -1)
            
        
    

